2025-04-12 02:41:07,079 - tdnn_trainer - INFO - Starting TDNN implementation
2025-04-12 02:41:07,079 - tdnn_trainer - INFO - Using data from: /Users/ca5/Desktop/qnn_fnl/data_filtered-1.csv
2025-04-12 02:41:07,079 - tdnn_trainer - INFO - Loading dataset from /Users/ca5/Desktop/qnn_fnl/data_filtered-1.csv
2025-04-12 02:41:07,085 - tdnn_trainer - INFO - Dataset loaded successfully: (1360, 40)
2025-04-12 02:41:07,085 - tdnn_trainer - INFO - NaN values in dataset: 0
2025-04-12 02:41:07,086 - tdnn_trainer - INFO - Dataset shape after dropping NaN: (1360, 40)
2025-04-12 02:41:07,087 - tdnn_trainer - INFO - Numerical columns: 32
2025-04-12 02:41:07,087 - tdnn_trainer - INFO - Categorical columns: 7
2025-04-12 02:41:07,088 - tdnn_trainer - INFO - Train set: (1088, 39), Test set: (272, 39)
2025-04-12 02:41:07,118 - tdnn_trainer - INFO - Model created with input size: 1825, hidden size: 128
2025-04-12 02:41:07,118 - tdnn_trainer - INFO - Model architecture: TDNN(
  (reshape_layer): Linear(in_features=1825, out_features=128, bias=True)
  (conv_layers): ModuleList(
    (0): Sequential(
      (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU()
      (3): Dropout(p=0.3, inplace=False)
    )
    (1): Sequential(
      (0): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU()
      (3): Dropout(p=0.3, inplace=False)
    )
    (2): Sequential(
      (0): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU()
      (3): Dropout(p=0.3, inplace=False)
    )
  )
  (fc1): Sequential(
    (0): Linear(in_features=384, out_features=128, bias=True)
    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): SiLU()
    (3): Dropout(p=0.3, inplace=False)
  )
  (fc2): Sequential(
    (0): Linear(in_features=128, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): SiLU()
    (3): Dropout(p=0.24, inplace=False)
  )
  (output_layer): Linear(in_features=64, out_features=1, bias=True)
)
2025-04-12 02:41:07,682 - tdnn_trainer - INFO - Starting training for 150 epochs...
2025-04-12 02:41:07,702 - tdnn_trainer - ERROR - Error in TDNN implementation: Given groups=1, weight of size [128, 128, 3], expected input[32, 1, 128] to have 128 channels, but got 1 channels instead
Traceback (most recent call last):
  File "/Users/ca5/Desktop/qnn_fnl/classical/Time Delay Neural Network (TDNN)/tdnn.py", line 426, in main
    model, train_losses, test_losses = train_model(
  File "/Users/ca5/Desktop/qnn_fnl/classical/Time Delay Neural Network (TDNN)/tdnn.py", line 218, in train_model
    outputs = model(inputs)
  File "/Users/ca5/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/ca5/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/ca5/Desktop/qnn_fnl/classical/Time Delay Neural Network (TDNN)/tdnn.py", line 113, in forward
    conv_out = conv(x)
  File "/Users/ca5/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/ca5/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/ca5/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/Users/ca5/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/ca5/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/ca5/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/conv.py", line 375, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/Users/ca5/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/conv.py", line 370, in _conv_forward
    return F.conv1d(
RuntimeError: Given groups=1, weight of size [128, 128, 3], expected input[32, 1, 128] to have 128 channels, but got 1 channels instead
2025-04-12 02:41:58,991 - tdnn_trainer - INFO - Starting TDNN implementation
2025-04-12 02:41:58,991 - tdnn_trainer - INFO - Using data from: /Users/ca5/Desktop/qnn_fnl/data_filtered-1.csv
2025-04-12 02:41:58,991 - tdnn_trainer - INFO - Loading dataset from /Users/ca5/Desktop/qnn_fnl/data_filtered-1.csv
2025-04-12 02:41:58,995 - tdnn_trainer - INFO - Dataset loaded successfully: (1360, 40)
2025-04-12 02:41:58,995 - tdnn_trainer - INFO - NaN values in dataset: 0
2025-04-12 02:41:58,995 - tdnn_trainer - INFO - Dataset shape after dropping NaN: (1360, 40)
2025-04-12 02:41:58,996 - tdnn_trainer - INFO - Numerical columns: 32
2025-04-12 02:41:58,996 - tdnn_trainer - INFO - Categorical columns: 7
2025-04-12 02:41:58,996 - tdnn_trainer - INFO - Train set: (1088, 39), Test set: (272, 39)
2025-04-12 02:41:59,012 - tdnn_trainer - INFO - Model created with input size: 1825, hidden size: 128
2025-04-12 02:41:59,012 - tdnn_trainer - INFO - Model architecture: TDNN(
  (reshape_layer): Linear(in_features=1825, out_features=128, bias=True)
  (conv_layers): ModuleList(
    (0): Sequential(
      (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU()
      (3): Dropout(p=0.3, inplace=False)
    )
    (1): Sequential(
      (0): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU()
      (3): Dropout(p=0.3, inplace=False)
    )
    (2): Sequential(
      (0): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU()
      (3): Dropout(p=0.3, inplace=False)
    )
  )
  (fc1): Sequential(
    (0): Linear(in_features=384, out_features=128, bias=True)
    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): SiLU()
    (3): Dropout(p=0.3, inplace=False)
  )
  (fc2): Sequential(
    (0): Linear(in_features=128, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): SiLU()
    (3): Dropout(p=0.24, inplace=False)
  )
  (output_layer): Linear(in_features=64, out_features=1, bias=True)
)
2025-04-12 02:41:59,456 - tdnn_trainer - INFO - Starting training for 150 epochs...
2025-04-12 02:42:02,498 - tdnn_trainer - INFO - Epoch [10/150], Train Loss: 0.0725, Test Loss: 0.0379
2025-04-12 02:42:05,500 - tdnn_trainer - INFO - Epoch [20/150], Train Loss: 0.0537, Test Loss: 0.0364
2025-04-12 02:42:07,602 - tdnn_trainer - INFO - Early stopping triggered after 27 epochs
2025-04-12 02:42:07,602 - tdnn_trainer - INFO - Loaded best model from training
2025-04-12 02:42:07,629 - tdnn_trainer - INFO - Test MSE: 331.9145
2025-04-12 02:42:07,629 - tdnn_trainer - INFO - Test RMSE: 18.2185
2025-04-12 02:42:07,629 - tdnn_trainer - INFO - Test MAE: 12.9150
2025-04-12 02:42:07,629 - tdnn_trainer - INFO - Test RÂ²: 0.9746
2025-04-12 02:42:07,629 - tdnn_trainer - INFO - Pearson Correlation: 0.9881
2025-04-12 02:42:07,859 - tdnn_trainer - INFO - Learning curve plot saved to 'tdnn_learning_curve.png'
2025-04-12 02:42:08,020 - tdnn_trainer - INFO - Actual vs predicted plot saved to 'tdnn_actual_vs_predicted.png'
2025-04-12 02:42:08,128 - tdnn_trainer - INFO - Error distribution plot saved to 'tdnn_error_distribution.png'
2025-04-12 02:42:08,290 - tdnn_trainer - INFO - Confidence intervals plot saved to 'tdnn_confidence_intervals.png'
2025-04-12 02:42:08,408 - tdnn_trainer - INFO - Residuals plot saved to 'tdnn_residuals.png'
2025-04-12 02:42:08,412 - tdnn_trainer - INFO - Model saved to tdnn_model_20250412_024208.pt
2025-04-12 02:42:08,412 - tdnn_trainer - INFO - TDNN implementation completed successfully
